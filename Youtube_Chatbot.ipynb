{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNorQShGFQU+0w/rPS+2DI4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akataruka/YouTube_ChatBot_RAG/blob/main/Youtube_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jUUlnF4kPPuB"
      },
      "outputs": [],
      "source": [
        "# Installing the libraries\n",
        "!pip install -q youtube-transcript-api langchain-community langchain faiss-cpu tiktoken python-dotenv sentence-transformers langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Dependencies\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "4ECCIVshQMfU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_youtube_video_id(url):\n",
        "    \"\"\"\n",
        "    Function to extract the video id from teh youtube video link\n",
        "    \"\"\"\n",
        "    pattern = r\"(?:youtube\\.com/(?:watch\\?v=|embed/|v/)|youtu\\.be/)([a-zA-Z0-9_-]{11})\"\n",
        "    match = re.search(pattern, url)\n",
        "    return match.group(1) if match else None"
      ],
      "metadata": {
        "id": "zHyyTdQP2U7X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transcript by using the video id\n",
        "def get_transcript(video_id,):\n",
        "  try:\n",
        "    transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages= [\"en\"])\n",
        "\n",
        "    # Flatten it to plain text\n",
        "    transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
        "    return transcript\n",
        "\n",
        "  except (TranscriptsDisabled, NoTranscriptFound):\n",
        "        print(\"No transcript available for this video.\")\n",
        "        return None\n",
        "  except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "hmsKhq907NSA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunks(transcript, chunk_size = 1000, overlap = 200):\n",
        "  splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = splitter.create_documents([transcript])\n",
        "  print(\"No of chuncks : \", len(chunks))\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "DnzAle8T8eLA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ],
      "metadata": {
        "id": "zcpkkmGQ7rIw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "video_url = input(\"Enter the Url\")\n",
        "if video_url:\n",
        "  video_id = extract_youtube_video_id(video_url)\n",
        "  if video_id == None:\n",
        "    print(\"Invalid URL\")\n",
        "    sys.exit()\n",
        "  print(\"Video id is : \", video_id)\n",
        "  transcript = get_transcript(video_id)  # Get the transcipt of the video\n",
        "  if transcript == None:\n",
        "    sys.exit()\n",
        "  print(\"Transcript Extracted\")\n",
        "  # print(transcript)\n",
        "  chunks = get_chunks(transcript)  # Tokenize the transcript\n",
        "  print(\"Chunks Created\")\n",
        "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # Create the embedding model class\n",
        "\n",
        "  # Create the FAISS vector store using the free embeddings\n",
        "  vector_store = FAISS.from_documents(chunks, embeddings)   # get the embeddings and create the vector store\n",
        "  retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # create the retriver class to get relevant docs\n",
        "\n",
        "else:\n",
        "  print(\"Enter valid URL\")\n",
        "\n",
        "# Initialise the llm modle class\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=GROQ_API_KEY,   # Replace with your actual API key or use env var\n",
        "    model_name=\"llama3-70b-8192\",       # Groq's LLaMA3 model\n",
        "    temperature=0.2\n",
        ")\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")\n",
        "\n",
        "print(\"You are all set now u can ask AI to assist you\")\n"
      ],
      "metadata": {
        "id": "H40PlxKLQUE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  question = input(\"ASK AI : \")\n",
        "  if question == None:\n",
        "    continue\n",
        "  if question == \"q\":\n",
        "    break\n",
        "\n",
        "  parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "    })\n",
        "  parser = StrOutputParser()\n",
        "  main_chain = parallel_chain | prompt | llm | parser\n",
        "  result = main_chain.invoke(question)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "BLwGTYjP6t8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}